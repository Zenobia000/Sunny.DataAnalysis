{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./images/ML_01.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./images/ML_02.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./images/ML_03.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./images/ML_04.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 240, 240)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# read image data \n",
    "s='./data/'  \n",
    "num=100 #number of sample\n",
    "row=240 #number of row\n",
    "col=240 #number of column\n",
    "images = np.zeros((num,row,col)) \n",
    "\n",
    "n=0 \n",
    "for i in range(0,10):\n",
    "    for j in range(1,11):\n",
    "        images[n,:,:]=cv2.imread(s+str(i)+'/'+str(i)+'-'+str(j)+'.bmp',0)\n",
    "        n=n+1\n",
    "\n",
    "print(images.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 36)\n",
      "(100,)\n",
      "[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3\n",
      " 3 3 3 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 6 6 6 6 6 6 6 6 6 6 7 7 7 7\n",
      " 7 7 7 7 7 7 8 8 8 8 8 8 8 8 8 8 9 9 9 9 9 9 9 9 9 9]\n"
     ]
    }
   ],
   "source": [
    "# extract each image as feature vector\n",
    "# use 6*6 grid to represent origin image\n",
    "\n",
    "feature = np.zeros((num,round(row/40),round(col/40))) \n",
    "for ni in range(0,num):\n",
    "    for nr in range(0,row):\n",
    "        for nc in range(0,col):\n",
    "            if images[ni,nr,nc]==0:\n",
    "                feature[ni,int(nr/40),int(nc/40)]+=1\n",
    "\n",
    "dataset = feature[:,:].reshape(-1,round(row/40)*round(col/40)).astype(np.float32) \n",
    "labels = np.asarray([int(i/10)  for i in range(0,100)])\n",
    "\n",
    "print(dataset.shape)\n",
    "print(labels.shape)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 36)\n",
      "(60,)\n",
      "(40, 36)\n",
      "(40,)\n",
      "[1 5 1 6 8 6 6 0 5 1 4 7 9 5 5 3 8 4 3 8 2 6 8 5 6 4 7 1 9 2 2 5 4 1 0 6 9\n",
      " 9 3 9 1 9 0 0 3 9 5 7 3 1 1 6 0 2 2 0 7 8 7 7]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# split data into training data and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset, labels, test_size=0.4)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 4 8 0 1 3 2 4 6 2 5 6 4 3 3 9 8 8 0 9 1 8 2 9 7 8 2 7 4 4 7 6 2 5 5 0 4\n",
      " 3 0 7]\n",
      "[6 4 8 0 1 5 2 4 6 7 5 6 4 5 5 9 5 8 1 9 1 8 7 7 7 8 2 7 1 4 7 6 1 5 5 0 4\n",
      " 5 0 7]\n",
      "number of correct sample: 28\n",
      "accuracy: 0.7\n",
      "confusion matrix: [[3 1 0 0 0 0 0 0 0 0]\n",
      " [0 2 0 0 0 0 0 0 0 0]\n",
      " [0 1 2 0 0 0 0 2 0 0]\n",
      " [0 0 0 0 0 4 1 0 0 0]\n",
      " [0 1 0 0 5 0 0 0 0 0]\n",
      " [0 0 0 0 0 3 0 0 0 0]\n",
      " [0 0 0 0 0 0 3 0 0 0]\n",
      " [0 0 0 0 0 0 0 4 0 0]\n",
      " [0 0 0 0 0 1 0 0 4 0]\n",
      " [0 0 0 0 0 0 0 1 0 2]]\n"
     ]
    }
   ],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "model = neighbors.KNeighborsClassifier(n_neighbors=10)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "X_test = scaler.transform(X_test)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "num_correct_samples = accuracy_score(y_test, y_pred, normalize=False)\n",
    "con_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print('number of correct sample: {}'.format(num_correct_samples))\n",
    "print('accuracy: {}'.format(accuracy))\n",
    "print('confusion matrix: {}'.format(con_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
